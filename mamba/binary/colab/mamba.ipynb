{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -U causal-conv1d\n",
        "!pip install bitsandbytes\n",
        "!pip install datasets evaluate accelerate\n",
        "!pip install --no-build-isolation --no-cache-dir -U mamba-ssm"
      ],
      "metadata": {
        "id": "29-du7v5CWSZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W_Q56UOsXjHr"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/getorca/mamba_for_sequence_classification.git\n",
        "!rm -rf mamba_for_sequence_classification/requirements.txt\n",
        "!touch mamba_for_sequence_classification/requirements.txt\n",
        "!pip install -q ./mamba_for_sequence_classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RqOLV5f4leSr"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AutoConfig, TrainingArguments, Trainer, DataCollatorWithPadding\n",
        "from datasets import load_dataset\n",
        "from mamba_ssm import selective_scan_fn\n",
        "from google.colab import drive\n",
        "from peft import LoraConfig, get_peft_model, TaskType\n",
        "from hf_mamba_classification import MambaForSequenceClassification\n",
        "import pandas as pd\n",
        "from datasets import Dataset, DatasetDict\n",
        "import os\n",
        "import evaluate\n",
        "import glob\n",
        "import inspect, os\n",
        "import math\n",
        "import torch\n",
        "os.environ[\"HF_DATASETS_CACHE\"] = \"/content/hf_cache\"\n",
        "MODEL_NAME = \"state-spaces/mamba-130m-hf\"\n",
        "NUM_LABELS = 2\n",
        "TRAIN_CSV = \"/content/train_clean.csv\"\n",
        "VAL_CSV   = \"/content/val_clean.csv\"\n",
        "OUTPUT_DIR = \"mamba_base_lora\"\n",
        "max_length = 128\n",
        "BATCH_SIZE = 32\n",
        "NUM_EPOCHS = 18\n",
        "LR = 2e-4\n",
        "LORA_R = 12\n",
        "LORA_ALPHA = 32\n",
        "LORA_DROP = 0.05"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1jSONOrUk3L6"
      },
      "outputs": [],
      "source": [
        "def train():\n",
        "\n",
        "    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "    id2label = {0: \"NEGATIVE\", 1: \"POSITIVE\"}\n",
        "    label2id = {\"NEGATIVE\": 0, \"POSITIVE\": 1}\n",
        "\n",
        "    model = MambaForSequenceClassification.from_pretrained(MODEL_NAME, num_labels = NUM_LABELS, use_cache = False, id2label = id2label, label2id = label2id)\n",
        "    model.to(\"cuda\")\n",
        "\n",
        "    train_df = pd.read_csv(TRAIN_CSV)\n",
        "    val_df   = pd.read_csv(VAL_CSV)\n",
        "\n",
        "    train_ds = Dataset.from_pandas(train_df)\n",
        "    val_ds   = Dataset.from_pandas(val_df)\n",
        "\n",
        "    raw_dataset = DatasetDict({\"train\": train_ds, \"validation\": val_ds})\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "\n",
        "    def preprocess(examples):\n",
        "        texts = [str(x) for x in examples[\"text\"]]\n",
        "        enc = tokenizer(\n",
        "            texts,\n",
        "            truncation=True,\n",
        "            padding=\"max_length\",\n",
        "            max_length=max_length,\n",
        "        )\n",
        "        enc[\"labels\"] = [int(x) for x in examples[\"label\"]]\n",
        "        return enc\n",
        "\n",
        "    dataset = raw_dataset.map(\n",
        "        preprocess,\n",
        "        batched=True,\n",
        "        remove_columns=[\"text\", \"label\"],\n",
        "    )\n",
        "\n",
        "    peft_config = LoraConfig(\n",
        "        task_type = TaskType.SEQ_CLS,\n",
        "        target_modules = [\"in_proj\", \"out_proj\", \"x_proj\", \"proj_in\", \"proj_out\"],\n",
        "        r = LORA_R,\n",
        "        lora_alpha = LORA_ALPHA,\n",
        "        lora_dropout = LORA_DROP,\n",
        "        bias = 'none'\n",
        "    )\n",
        "\n",
        "    final_model = get_peft_model(model, peft_config)\n",
        "    final_model.to(\"cuda\")\n",
        "    print(\" % OF TRAINING\")\n",
        "    final_model.print_trainable_parameters()\n",
        "\n",
        "    metric_acc = evaluate.load(\"accuracy\")\n",
        "    metric_f1  = evaluate.load(\"f1\")\n",
        "    metric_precision = evaluate.load(\"precision\")\n",
        "    metric_recall = evaluate.load(\"recall\")\n",
        "\n",
        "    def compute_metrics(p):\n",
        "      preds = p.predictions.argmax(-1)\n",
        "      return {\n",
        "          \"accuracy\": metric_acc.compute(predictions = preds, references = p.label_ids)[\"accuracy\"],\n",
        "          \"f1\":       metric_f1.compute(predictions = preds, references = p.label_ids, average = \"binary\")[\"f1\"],\n",
        "          \"precision\":       metric_precision.compute(predictions = preds, references = p.label_ids, average=\"binary\")[\"precision\"],\n",
        "          \"recall\":       metric_recall.compute(predictions = preds, references = p.label_ids, average=\"binary\")[\"recall\"],\n",
        "      }\n",
        "\n",
        "    final_model.gradient_checkpointing_enable()\n",
        "    torch.backends.cuda.matmul.allow_tf32 = True\n",
        "    torch.backends.cudnn.allow_tf32  = True\n",
        "    drive.mount('/content/drive')\n",
        "    OUTPUT_DIR_DRIVE = \"/content/drive/MyDrive/mamba_checkpoints\"\n",
        "    import os\n",
        "    os.makedirs(OUTPUT_DIR_DRIVE, exist_ok=True)\n",
        "    #final_model = torch.compile(final_model, mode=\"default\", fullgraph=False)\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir                  = OUTPUT_DIR_DRIVE,\n",
        "        per_device_train_batch_size = BATCH_SIZE,\n",
        "        learning_rate               = LR,\n",
        "        gradient_accumulation_steps = 8,\n",
        "        eval_strategy               = \"epoch\",\n",
        "        save_strategy               = \"epoch\",\n",
        "        dataloader_num_workers      = 2,\n",
        "        warmup_ratio                = 0.1,\n",
        "        lr_scheduler_type           = \"cosine\",\n",
        "        dataloader_pin_memory       = True,\n",
        "        bf16                        = True,\n",
        "        optim                       = \"adamw_torch_fused\",\n",
        "        max_grad_norm               = 1.0,\n",
        "        fp16                        = False,\n",
        "        num_train_epochs            = NUM_EPOCHS,\n",
        "        logging_strategy            = \"epoch\",\n",
        "        load_best_model_at_end      = True,\n",
        "        metric_for_best_model       = \"f1\",\n",
        "        remove_unused_columns       = False,\n",
        "        greater_is_better           = True,\n",
        "        report_to                   = \"none\",\n",
        "        label_names                 = [\"labels\"]\n",
        "    )\n",
        "\n",
        "    #final_model = torch.compile(final_model)\n",
        "    with torch.no_grad():\n",
        "      torch.nn.init.kaiming_uniform_(final_model.classifier.weight, a = math.sqrt(5))\n",
        "\n",
        "    trainer = Trainer(\n",
        "        model               = final_model,\n",
        "        args                = training_args,\n",
        "        train_dataset       = dataset[\"train\"],\n",
        "        tokenizer           = tokenizer,\n",
        "        eval_dataset        = dataset[\"validation\"],\n",
        "        data_collator       = DataCollatorWithPadding(tokenizer, return_tensors = 'pt'),\n",
        "        compute_metrics     = compute_metrics\n",
        "    )\n",
        "\n",
        "    all_ckpts = sorted(\n",
        "    glob.glob(os.path.join(OUTPUT_DIR_DRIVE, \"checkpoint-*\")),\n",
        "    key=lambda x: int(x.split(\"-\")[-1])\n",
        "    )\n",
        "    if all_ckpts:\n",
        "        print(\"ðŸ”„ Riprendo da:\", all_ckpts[-1])\n",
        "        trainer.train(resume_from_checkpoint=all_ckpts[-1])\n",
        "    else:\n",
        "        print(\"ðŸ”„ Nessun checkpoint trovato, inizio da zero\")\n",
        "        trainer.train()\n",
        "    metrics = trainer.evaluate()\n",
        "    print(\"Final evaluation:\", metrics)\n",
        "\n",
        "    trainer.save_model(os.path.join(OUTPUT_DIR_DRIVE, \"final_model\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EF8uoMannu9D"
      },
      "outputs": [],
      "source": [
        "train()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import logging\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from transformers import AutoTokenizer, DataCollatorWithPadding\n",
        "from peft import PeftModel\n",
        "from datasets import Dataset, DatasetDict\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    f1_score,\n",
        "    balanced_accuracy_score,\n",
        "    matthews_corrcoef,\n",
        "    roc_auc_score,\n",
        "    average_precision_score,\n",
        "    roc_curve,\n",
        "    precision_recall_curve,\n",
        "    cohen_kappa_score,\n",
        "    confusion_matrix,\n",
        "    auc\n",
        ")\n",
        "from hf_mamba_classification import MambaForSequenceClassification\n",
        "\n",
        "# CONFIGURATION\n",
        "MODEL_NAME = \"state-spaces/mamba-130m-hf\"\n",
        "ADAPTER_DIR = \"mamba_base_lora/final_model\"\n",
        "BATCH_SIZE = 32\n",
        "MAX_LENGTH = 128\n",
        "RESULTS_DIR = \"results\"\n",
        "DATA_DIR = Path(\"/content\")  # adjust as needed\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Set up logging\n",
        "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\")\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "def compute_probs_from_hf_dataset(\n",
        "    hf_dataset: Dataset,\n",
        "    model: torch.nn.Module,\n",
        "    tokenizer,\n",
        "    device: torch.device\n",
        ") -> np.ndarray:\n",
        "    collator = DataCollatorWithPadding(tokenizer, return_tensors=\"pt\")\n",
        "    pin_memory = device.type == \"cuda\"\n",
        "    loader = DataLoader(\n",
        "        hf_dataset,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        shuffle=False,\n",
        "        collate_fn=collator,\n",
        "        num_workers=2,\n",
        "        pin_memory=pin_memory\n",
        "    )\n",
        "    all_probs = []\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for batch in loader:\n",
        "            inputs = {k: v.to(device) for k, v in batch.items() if isinstance(v, torch.Tensor)}\n",
        "            logits = model(**inputs).logits\n",
        "            probs = torch.softmax(logits, dim=-1)[:, 1]\n",
        "            all_probs.append(probs.cpu().numpy())\n",
        "    return np.concatenate(all_probs, axis=0)\n",
        "\n",
        "\n",
        "def save_results_and_plots(\n",
        "    y_true: np.ndarray,\n",
        "    probs: np.ndarray,\n",
        "    set_name: str,\n",
        "    threshold: float,\n",
        "    out_dir: str = RESULTS_DIR\n",
        "):\n",
        "    # Create output directory\n",
        "    os.makedirs(out_dir, exist_ok=True)\n",
        "\n",
        "    # Compute predictions\n",
        "    y_pred = (probs >= threshold).astype(int)\n",
        "\n",
        "    # Compute confusion matrix components\n",
        "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
        "\n",
        "    # Collect metrics\n",
        "    metrics = {\n",
        "        \"Threshold\": threshold,\n",
        "        \"Accuracy\": accuracy_score(y_true, y_pred),\n",
        "        \"Balanced Accuracy\": balanced_accuracy_score(y_true, y_pred),\n",
        "        \"F1\": f1_score(y_true, y_pred),\n",
        "        \"Precision\": precision_score(y_true, y_pred),\n",
        "        \"Recall (Sensitivity)\": recall_score(y_true, y_pred),\n",
        "        \"Specificity\": tn / (tn + fp) if (tn + fp) > 0 else np.nan,\n",
        "        \"Negative Predictive Value\": tn / (tn + fn) if (tn + fn) > 0 else np.nan,\n",
        "        \"MCC\": matthews_corrcoef(y_true, y_pred),\n",
        "        \"Cohen Kappa\": cohen_kappa_score(y_true, y_pred),\n",
        "        \"ROC-AUC\": roc_auc_score(y_true, probs),\n",
        "        \"PR-AUC\": average_precision_score(y_true, probs)\n",
        "    }\n",
        "    metrics_df = pd.DataFrame([metrics])\n",
        "    metrics_path = os.path.join(out_dir, f\"{set_name}_metrics.csv\")\n",
        "    metrics_df.to_csv(metrics_path, index=False)\n",
        "\n",
        "    # Save per-sample probabilities and predictions\n",
        "    results_df = pd.DataFrame({\n",
        "        \"true_label\": y_true,\n",
        "        \"probability\": probs,\n",
        "        \"pred_label\": y_pred\n",
        "    })\n",
        "    results_path = os.path.join(out_dir, f\"{set_name}_predictions.csv\")\n",
        "    results_df.to_csv(results_path, index=False)\n",
        "\n",
        "    # ROC Curve\n",
        "    fpr, tpr, _ = roc_curve(y_true, probs)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    fig, ax = plt.subplots(figsize=(8, 6))\n",
        "    ax.plot(fpr, tpr, label=f\"AUC = {roc_auc:.3f}\", linewidth=2)\n",
        "    ax.plot([0, 1], [0, 1], linestyle=\"--\", color=\"gray\", linewidth=1)\n",
        "    ax.set(\n",
        "        xlabel=\"False Positive Rate\",\n",
        "        ylabel=\"True Positive Rate\",\n",
        "        title=f\"ROC Curve ({set_name})\"\n",
        "    )\n",
        "    ax.legend(loc=\"lower right\")\n",
        "    plt.tight_layout()\n",
        "    roc_path = os.path.join(out_dir, f\"{set_name}_roc_curve.png\")\n",
        "    fig.savefig(roc_path, dpi=300)\n",
        "    plt.close(fig)\n",
        "\n",
        "    # Precision-Recall Curve\n",
        "    precision, recall, _ = precision_recall_curve(y_true, probs)\n",
        "    pr_auc = auc(recall, precision)\n",
        "    fig, ax = plt.subplots(figsize=(8, 6))\n",
        "    ax.plot(recall, precision, label=f\"AP = {pr_auc:.3f}\", linewidth=2)\n",
        "    ax.set(\n",
        "        xlabel=\"Recall\",\n",
        "        ylabel=\"Precision\",\n",
        "        title=f\"Precisionâ€“Recall Curve ({set_name})\"\n",
        "    )\n",
        "    ax.legend(loc=\"upper right\")\n",
        "    plt.tight_layout()\n",
        "    pr_path = os.path.join(out_dir, f\"{set_name}_pr_curve.png\")\n",
        "    fig.savefig(pr_path, dpi=300)\n",
        "    plt.close(fig)\n",
        "\n",
        "    logger.info(f\"[Saved] {set_name} metrics -> {metrics_path}\")\n",
        "    logger.info(f\"[Saved] {set_name} predictions -> {results_path}\")\n",
        "    logger.info(f\"[Saved] {set_name} ROC curve -> {roc_path}\")\n",
        "    logger.info(f\"[Saved] {set_name} PR curve -> {pr_path}\")\n",
        "\n",
        "\n",
        "def main():\n",
        "    # Initialize tokenizer and model\n",
        "    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "    base_model = MambaForSequenceClassification.from_pretrained(\n",
        "        MODEL_NAME, num_labels=2, use_cache=False\n",
        "    )\n",
        "    model = PeftModel.from_pretrained(base_model, ADAPTER_DIR).to(device)\n",
        "\n",
        "    # Load data\n",
        "    test_df = pd.read_csv(DATA_DIR / \"test_clean.csv\")\n",
        "    val_df = pd.read_csv(DATA_DIR / \"val_clean.csv\")\n",
        "\n",
        "    test_ds = Dataset.from_pandas(test_df)\n",
        "    val_ds = Dataset.from_pandas(val_df)\n",
        "    raw_dataset = DatasetDict({\"test\": test_ds, \"val\": val_ds})\n",
        "\n",
        "    # Preprocessing function\n",
        "    def preprocess(examples):\n",
        "        texts = [str(x) for x in examples[\"text\"]]\n",
        "        encodings = tokenizer(\n",
        "            texts,\n",
        "            truncation=True,\n",
        "            padding=\"max_length\",\n",
        "            max_length=MAX_LENGTH\n",
        "        )\n",
        "        encodings[\"labels\"] = [int(x) for x in examples[\"label\"]]\n",
        "        return encodings\n",
        "\n",
        "    # Tokenize datasets\n",
        "    dataset = raw_dataset.map(\n",
        "        preprocess,\n",
        "        batched=True,\n",
        "        remove_columns=[\"text\", \"label\"]\n",
        "    )\n",
        "\n",
        "    # Extract splits\n",
        "    y_val = np.array(dataset[\"val\"][\"labels\"])\n",
        "    y_test = np.array(dataset[\"test\"][\"labels\"])\n",
        "\n",
        "    # Compute validation probabilities and find optimal threshold\n",
        "    probs_val = compute_probs_from_hf_dataset(dataset[\"val\"], model, tokenizer, device)\n",
        "    fpr, tpr, thresholds = roc_curve(y_val, probs_val)\n",
        "    youden_j = tpr - fpr\n",
        "    best_idx = np.argmax(youden_j)\n",
        "    best_thresh = thresholds[best_idx]\n",
        "    logger.info(f\"Optimal threshold from validation: {best_thresh:.3f}\")\n",
        "\n",
        "    # Compute test probabilities\n",
        "    probs_test = compute_probs_from_hf_dataset(dataset[\"test\"], model, tokenizer, device)\n",
        "\n",
        "    # Save results and plots\n",
        "    save_results_and_plots(y_test, probs_test, set_name=\"test_youden\", threshold=best_thresh)\n",
        "    save_results_and_plots(y_test, probs_test, set_name=\"test_standard\", threshold=0.5)"
      ],
      "metadata": {
        "id": "NdAbgwV7wFxZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HmVIdy5Anxqt"
      },
      "outputs": [],
      "source": [
        "test()\n",
        "!zip -r results.zip /content/results"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}