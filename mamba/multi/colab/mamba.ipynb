{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -U causal-conv1d\n",
        "!pip install bitsandbytes\n",
        "!pip install datasets evaluate accelerate\n",
        "!pip install --no-build-isolation --no-cache-dir -U mamba-ssm"
      ],
      "metadata": {
        "id": "29-du7v5CWSZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W_Q56UOsXjHr"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/getorca/mamba_for_sequence_classification.git\n",
        "!rm -rf mamba_for_sequence_classification/requirements.txt\n",
        "!touch mamba_for_sequence_classification/requirements.txt\n",
        "!pip install -q ./mamba_for_sequence_classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RqOLV5f4leSr"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AutoConfig, TrainingArguments, Trainer, DataCollatorWithPadding\n",
        "from datasets import load_dataset\n",
        "from mamba_ssm import selective_scan_fn\n",
        "from google.colab import drive\n",
        "from peft import LoraConfig, get_peft_model, TaskType\n",
        "from hf_mamba_classification import MambaForSequenceClassification\n",
        "import pandas as pd\n",
        "from datasets import Dataset, DatasetDict\n",
        "import os\n",
        "import evaluate\n",
        "import glob\n",
        "import inspect, os\n",
        "import math\n",
        "import torch\n",
        "os.environ[\"HF_DATASETS_CACHE\"] = \"/content/hf_cache\"\n",
        "MODEL_NAME = \"state-spaces/mamba-130m-hf\"\n",
        "NUM_LABELS = 5\n",
        "TRAIN_CSV = \"/content/train_clean.csv\"\n",
        "VAL_CSV   = \"/content/val_clean.csv\"\n",
        "OUTPUT_DIR = \"mamba_base_lora\"\n",
        "max_length = 128\n",
        "BATCH_SIZE = 32\n",
        "NUM_EPOCHS = 21\n",
        "LR = 2e-4\n",
        "LORA_R = 12\n",
        "LORA_ALPHA = 32\n",
        "LORA_DROP = 0.05"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1jSONOrUk3L6"
      },
      "outputs": [],
      "source": [
        "def train():\n",
        "\n",
        "    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "    id2label = {0 : \"age\", 1 : \"ethnicity\", 2 : \"gender\", 3 : \"not_cyberbullying\", 4 : \"religion\"}\n",
        "    label2id = {\"age\": 0, \"ethnicity\": 1, \"gender\": 2, \"not_cyberbullying\": 3, \"religion\": 4}\n",
        "\n",
        "    model = MambaForSequenceClassification.from_pretrained(MODEL_NAME, num_labels = NUM_LABELS, use_cache = False, id2label = id2label, label2id = label2id)\n",
        "    model.to(\"cuda\")\n",
        "\n",
        "    train_df = pd.read_csv(TRAIN_CSV)\n",
        "    val_df   = pd.read_csv(VAL_CSV)\n",
        "\n",
        "    train_ds = Dataset.from_pandas(train_df)\n",
        "    val_ds   = Dataset.from_pandas(val_df)\n",
        "\n",
        "    raw_dataset = DatasetDict({\"train\": train_ds, \"validation\": val_ds})\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "\n",
        "    def preprocess(examples):\n",
        "        texts = [str(x) for x in examples[\"text\"]]\n",
        "        enc = tokenizer(\n",
        "            texts,\n",
        "            truncation=True,\n",
        "            padding=\"max_length\",\n",
        "            max_length=max_length,\n",
        "        )\n",
        "        enc[\"labels\"] = [int(x) for x in examples[\"label\"]]\n",
        "        return enc\n",
        "\n",
        "    dataset = raw_dataset.map(\n",
        "        preprocess,\n",
        "        batched=True,\n",
        "        remove_columns=[\"text\", \"label\"],\n",
        "    )\n",
        "\n",
        "    peft_config = LoraConfig(\n",
        "        task_type = TaskType.SEQ_CLS,\n",
        "        target_modules = [\"in_proj\", \"out_proj\", \"x_proj\", \"proj_in\", \"proj_out\"],\n",
        "        r = LORA_R,\n",
        "        lora_alpha = LORA_ALPHA,\n",
        "        lora_dropout = LORA_DROP,\n",
        "        bias = 'none'\n",
        "    )\n",
        "\n",
        "    final_model = get_peft_model(model, peft_config)\n",
        "    final_model.to(\"cuda\")\n",
        "    print(\" % OF TRAINING\")\n",
        "    final_model.print_trainable_parameters()\n",
        "\n",
        "    metric_acc = evaluate.load(\"accuracy\")\n",
        "    metric_f1  = evaluate.load(\"f1\")\n",
        "    metric_precision = evaluate.load(\"precision\")\n",
        "    metric_recall = evaluate.load(\"recall\")\n",
        "\n",
        "    def compute_metrics(p):\n",
        "      preds = p.predictions.argmax(-1)\n",
        "      return {\n",
        "          \"accuracy\": metric_acc.compute(predictions = preds, references = p.label_ids)[\"accuracy\"],\n",
        "          \"f1\":       metric_f1.compute(predictions = preds, references = p.label_ids, average = \"macro\")[\"f1\"],\n",
        "          \"precision\":       metric_precision.compute(predictions = preds, references = p.label_ids, average=\"macro\")[\"precision\"],\n",
        "          \"recall\":       metric_recall.compute(predictions = preds, references = p.label_ids, average=\"macro\")[\"recall\"],\n",
        "      }\n",
        "\n",
        "    final_model.gradient_checkpointing_enable()\n",
        "    torch.backends.cuda.matmul.allow_tf32 = True\n",
        "    torch.backends.cudnn.allow_tf32  = True\n",
        "    drive.mount('/content/drive')\n",
        "    OUTPUT_DIR_DRIVE = \"/content/drive/MyDrive/mamba_checkpoints/multi_class_final/\"\n",
        "    import os\n",
        "    os.makedirs(OUTPUT_DIR_DRIVE, exist_ok=True)\n",
        "    #final_model = torch.compile(final_model, mode=\"default\", fullgraph=False)\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir                  = OUTPUT_DIR_DRIVE,\n",
        "        per_device_train_batch_size = BATCH_SIZE,\n",
        "        learning_rate               = LR,\n",
        "        gradient_accumulation_steps = 8,\n",
        "        eval_strategy               = \"epoch\",\n",
        "        save_strategy               = \"epoch\",\n",
        "        dataloader_num_workers      = 2,\n",
        "        warmup_ratio                = 0.1,\n",
        "        lr_scheduler_type           = \"cosine\",\n",
        "        dataloader_pin_memory       = True,\n",
        "        bf16                        = True,\n",
        "        optim                       = \"adamw_torch_fused\",\n",
        "        max_grad_norm               = 1.0,\n",
        "        fp16                        = False,\n",
        "        num_train_epochs            = NUM_EPOCHS,\n",
        "        logging_strategy            = \"epoch\",\n",
        "        load_best_model_at_end      = True,\n",
        "        metric_for_best_model       = \"f1\",\n",
        "        remove_unused_columns       = False,\n",
        "        greater_is_better           = True,\n",
        "        report_to                   = \"none\",\n",
        "        label_names                 = [\"labels\"]\n",
        "    )\n",
        "\n",
        "    #final_model = torch.compile(final_model)\n",
        "    with torch.no_grad():\n",
        "      torch.nn.init.kaiming_uniform_(final_model.classifier.weight, a = math.sqrt(5))\n",
        "\n",
        "    trainer = Trainer(\n",
        "        model               = final_model,\n",
        "        args                = training_args,\n",
        "        train_dataset       = dataset[\"train\"],\n",
        "        tokenizer           = tokenizer,\n",
        "        eval_dataset        = dataset[\"validation\"],\n",
        "        data_collator       = DataCollatorWithPadding(tokenizer, return_tensors = 'pt'),\n",
        "        compute_metrics     = compute_metrics\n",
        "    )\n",
        "\n",
        "    all_ckpts = sorted(\n",
        "    glob.glob(os.path.join(OUTPUT_DIR_DRIVE, \"checkpoint-*\")),\n",
        "    key=lambda x: int(x.split(\"-\")[-1])\n",
        "    )\n",
        "    if all_ckpts:\n",
        "        print(\"ðŸ”„ Riprendo da:\", all_ckpts[-1])\n",
        "        trainer.train(resume_from_checkpoint=all_ckpts[-1])\n",
        "    else:\n",
        "        print(\"ðŸ”„ Nessun checkpoint trovato, inizio da zero\")\n",
        "        trainer.train()\n",
        "    metrics = trainer.evaluate()\n",
        "    print(\"Final evaluation:\", metrics)\n",
        "\n",
        "    trainer.save_model(os.path.join(OUTPUT_DIR_DRIVE, \"final_model\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EF8uoMannu9D"
      },
      "outputs": [],
      "source": [
        "train()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import logging\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from transformers import AutoTokenizer, DataCollatorWithPadding\n",
        "from peft import PeftModel\n",
        "from datasets import Dataset, DatasetDict\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    f1_score,\n",
        "    confusion_matrix,\n",
        "    roc_auc_score,\n",
        "    roc_curve,\n",
        "    average_precision_score,\n",
        "    auc\n",
        ")\n",
        "from sklearn.preprocessing import label_binarize\n",
        "from hf_mamba_classification import MambaForSequenceClassification\n",
        "\n",
        "# CONFIGURATION\n",
        "MODEL_NAME = \"state-spaces/mamba-130m-hf\"\n",
        "ADAPTER_DIR = \"/content/drive/MyDrive/mamba_checkpoints/multi_class_final/final_model/\"\n",
        "BATCH_SIZE = 32\n",
        "MAX_LENGTH = 128\n",
        "RESULTS_DIR = \"results\"\n",
        "DATA_DIR = Path(\"/content\")  # adjust as needed\n",
        "NUM_LABELS = 5  # set the number of classes here\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Set up logging\n",
        "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\")\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "def compute_probs_from_hf_dataset(\n",
        "    hf_dataset: Dataset,\n",
        "    model: torch.nn.Module,\n",
        "    tokenizer,\n",
        "    device: torch.device\n",
        ") -> np.ndarray:\n",
        "    collator = DataCollatorWithPadding(tokenizer, return_tensors=\"pt\")\n",
        "    pin_memory = device.type == \"cuda\"\n",
        "    loader = DataLoader(\n",
        "        hf_dataset,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        shuffle=False,\n",
        "        collate_fn=collator,\n",
        "        num_workers=2,\n",
        "        pin_memory=pin_memory\n",
        "    )\n",
        "    all_probs = []\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for batch in loader:\n",
        "            inputs = {k: v.to(device) for k, v in batch.items() if isinstance(v, torch.Tensor)}\n",
        "            logits = model(**inputs).logits\n",
        "            probs = torch.softmax(logits, dim=-1)\n",
        "            all_probs.append(probs.cpu().numpy())\n",
        "    return np.concatenate(all_probs, axis=0)\n",
        "\n",
        "\n",
        "def save_results_and_plots_multiclass(\n",
        "    y_true: np.ndarray,\n",
        "    probs: np.ndarray,\n",
        "    set_name: str,\n",
        "    out_dir: str = RESULTS_DIR\n",
        "):\n",
        "    # Create output directory\n",
        "    os.makedirs(out_dir, exist_ok=True)\n",
        "\n",
        "    # Predictions\n",
        "    y_pred = np.argmax(probs, axis=1)\n",
        "\n",
        "    # Confusion matrix\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "    # Metrics\n",
        "    metrics = {\n",
        "        \"Accuracy\": accuracy_score(y_true, y_pred),\n",
        "        \"Precision (macro)\": precision_score(y_true, y_pred, average=\"macro\", zero_division=0),\n",
        "        \"Recall (macro)\": recall_score(y_true, y_pred, average=\"macro\", zero_division=0),\n",
        "        \"F1 (macro)\": f1_score(y_true, y_pred, average=\"macro\", zero_division=0),\n",
        "        \"ROC-AUC (ovr)\": roc_auc_score(y_true, probs, multi_class=\"ovr\", average=\"macro\")\n",
        "    }\n",
        "    metrics_df = pd.DataFrame([metrics])\n",
        "    metrics_path = os.path.join(out_dir, f\"{set_name}_metrics.csv\")\n",
        "    metrics_df.to_csv(metrics_path, index=False)\n",
        "\n",
        "    # Save per-sample probabilities and predictions\n",
        "    results_df = pd.DataFrame({\n",
        "        \"true_label\": y_true,\n",
        "        **{f\"prob_class_{i}\": probs[:, i] for i in range(probs.shape[1])},\n",
        "        \"pred_label\": y_pred\n",
        "    })\n",
        "    results_path = os.path.join(out_dir, f\"{set_name}_predictions.csv\")\n",
        "    results_df.to_csv(results_path, index=False)\n",
        "\n",
        "    # Plot and save confusion matrix\n",
        "    fig, ax = plt.subplots(figsize=(8, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", ax=ax)\n",
        "    ax.set(\n",
        "        xlabel=\"Predicted label\",\n",
        "        ylabel=\"True label\",\n",
        "        title=f\"Confusion Matrix ({set_name})\"\n",
        "    )\n",
        "    ax.grid(True)\n",
        "    plt.tight_layout()\n",
        "    cm_path = os.path.join(out_dir, f\"{set_name}_confusion_matrix.png\")\n",
        "    fig.savefig(cm_path, dpi=300)\n",
        "    plt.close(fig)\n",
        "\n",
        "    # One-vs-rest ROC curves for each class with grid\n",
        "    y_true_bin = label_binarize(y_true, classes=list(range(probs.shape[1])))\n",
        "    fig, ax = plt.subplots(figsize=(8, 6))\n",
        "    for i in range(probs.shape[1]):\n",
        "        fpr, tpr, _ = roc_curve(y_true_bin[:, i], probs[:, i])\n",
        "        roc_auc_i = auc(fpr, tpr)\n",
        "        ax.plot(fpr, tpr, label=f\"Class {i} (AUC={roc_auc_i:.2f})\")\n",
        "    ax.plot([0, 1], [0, 1], linestyle=\"--\", linewidth=1)\n",
        "    ax.set(\n",
        "        xlabel=\"False Positive Rate\",\n",
        "        ylabel=\"True Positive Rate\",\n",
        "        title=f\"ROC Curves ({set_name})\"\n",
        "    )\n",
        "    ax.grid(True)\n",
        "    ax.legend(loc=\"lower right\")\n",
        "    plt.tight_layout()\n",
        "    roc_multi_path = os.path.join(out_dir, f\"{set_name}_roc_multiclass.png\")\n",
        "    fig.savefig(roc_multi_path, dpi=300)\n",
        "    plt.close(fig)\n",
        "\n",
        "    logger.info(f\"[Saved] {set_name} metrics -> {metrics_path}\")\n",
        "    logger.info(f\"[Saved] {set_name} predictions -> {results_path}\")\n",
        "    logger.info(f\"[Saved] {set_name} confusion matrix -> {cm_path}\")\n",
        "    logger.info(f\"[Saved] {set_name} multiclass ROC -> {roc_multi_path}\")\n",
        "\n",
        "\n",
        "def test():\n",
        "    # Initialize tokenizer and model\n",
        "    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "    base_model = MambaForSequenceClassification.from_pretrained(\n",
        "        MODEL_NAME,\n",
        "        num_labels=NUM_LABELS,\n",
        "        use_cache=False\n",
        "    )\n",
        "    model = PeftModel.from_pretrained(base_model, ADAPTER_DIR).to(device)\n",
        "\n",
        "    # Load data\n",
        "    test_df = pd.read_csv(DATA_DIR / \"test_clean.csv\")\n",
        "    val_df = pd.read_csv(DATA_DIR / \"val_clean.csv\")\n",
        "\n",
        "    test_ds = Dataset.from_pandas(test_df)\n",
        "    val_ds = Dataset.from_pandas(val_df)\n",
        "    raw_dataset = DatasetDict({\"test\": test_ds, \"val\": val_ds})\n",
        "\n",
        "    # Preprocessing function\n",
        "    def preprocess(examples):\n",
        "        texts = [str(x) for x in examples[\"text\"]]\n",
        "        encodings = tokenizer(\n",
        "            texts,\n",
        "            truncation=True,\n",
        "            padding=\"max_length\",\n",
        "            max_length=MAX_LENGTH\n",
        "        )\n",
        "        encodings[\"labels\"] = [int(x) for x in examples[\"label\"]]\n",
        "        return encodings\n",
        "\n",
        "    # Tokenize datasets\n",
        "    dataset = raw_dataset.map(\n",
        "        preprocess,\n",
        "        batched=True,\n",
        "        remove_columns=[\"text\", \"label\"]\n",
        "    )\n",
        "\n",
        "    # Extract splits\n",
        "    y_val = np.array(dataset[\"val\"][\"labels\"])\n",
        "    y_test = np.array(dataset[\"test\"][\"labels\"])\n",
        "\n",
        "    # Compute validation and test probabilities\n",
        "    _ = compute_probs_from_hf_dataset(dataset[\"val\"], model, tokenizer, device)\n",
        "    probs_test = compute_probs_from_hf_dataset(dataset[\"test\"], model, tokenizer, device)\n",
        "\n",
        "    # Save results and plots\n",
        "    save_results_and_plots_multiclass(y_test, probs_test, set_name=\"test\")"
      ],
      "metadata": {
        "id": "oWf1OhKgCXo7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HmVIdy5Anxqt"
      },
      "outputs": [],
      "source": [
        "test()\n",
        "!zip -r results.zip /content/results"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}