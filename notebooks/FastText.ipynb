{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_3_qQNGmlCoL",
        "outputId": "d1e4fe02-3ff8-44fd-b171-ec71625973ba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: fasttext in /usr/local/lib/python3.11/dist-packages (0.9.3)\n",
            "Requirement already satisfied: pybind11>=2.2 in /usr/local/lib/python3.11/dist-packages (from fasttext) (2.13.6)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from fasttext) (75.2.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from fasttext) (1.24.4)\n",
            "Requirement already satisfied: numpy==1.24.4 in /usr/local/lib/python3.11/dist-packages (1.24.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install fasttext\n",
        "!pip install numpy==1.24.4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uFzG4ORblGQM"
      },
      "outputs": [],
      "source": [
        "import fasttext\n",
        "import csv\n",
        "import os\n",
        "import time\n",
        "import math\n",
        "from collections import defaultdict\n",
        "\n",
        "MODE = \"multiclass\" # \"binary\" #\n",
        "OVERRIDE = True # Rewrites all .txt datasets\n",
        "\n",
        "ARTIFACTS = \"/content/drive/MyDrive/HLT_artifacts\"\n",
        "DATASET = f\"{ARTIFACTS}/datasets\"\n",
        "TRAINING = f\"{DATASET}/train_{MODE}\"\n",
        "VALIDATION = f\"{DATASET}/validation_{MODE}\"\n",
        "TEST = f\"{DATASET}/test_{MODE}\"\n",
        "\n",
        "FAST_TEXT = f\"{ARTIFACTS}/base_models/fasttext\"\n",
        "FINE_TUNED = f\"{ARTIFACTS}/fine-tuned_models/fasttext-{MODE}.bin\"\n",
        "TMP = \"/content\"\n",
        "\n",
        "PRETRAINED_DIM=300 # When ValueError: Dimension of pretrained vectors (x) does not match dimension (y)! set this var to x\n",
        "BENCHMARK_TIME_LIMIT = 60 * 1\n",
        "\n",
        "EPOCHS = [18, 22]\n",
        "PATIENCE = 2\n",
        "LR = 1e-2\n",
        "\n",
        "INPUT_COL = \"tweet_text\"\n",
        "OUT_COL = \"label\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qI196AK1naW0"
      },
      "outputs": [],
      "source": [
        "def macro_f1(cm):\n",
        "    labels = sorted(set([k[0] for k in cm] + [k[1] for k in cm]))\n",
        "    f1s = []\n",
        "    for label in labels:\n",
        "        tp = cm.get((label, label), 0)\n",
        "        fp = sum(cm.get((other, label), 0) for other in labels if other != label)\n",
        "        fn = sum(cm.get((label, other), 0) for other in labels if other != label)\n",
        "\n",
        "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
        "        recall    = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "        f1        = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
        "        f1s.append(f1)\n",
        "\n",
        "    return sum(f1s) / len(f1s) if f1s else 0.0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sNq3e74okKDi"
      },
      "outputs": [],
      "source": [
        "class FineFastText:\n",
        "    def __init__(self, model_path: str | None = None) -> None:\n",
        "        self.model = None\n",
        "        if model_path is not None:\n",
        "          self.model = fasttext.load_model(model_path + \".bin\")\n",
        "\n",
        "    def validate(self, dataset = VALIDATION) -> dict:\n",
        "      \"\"\"\n",
        "      Validation phase. Works for binary and multi-class.\n",
        "      Returns:\n",
        "          - loss (sum)\n",
        "          - confusion matrix as a dict: cm[(true, pred)] = count\n",
        "      \"\"\"\n",
        "      cm = defaultdict(int)\n",
        "      n_samples = 0\n",
        "\n",
        "      with open(f\"{dataset}.txt\", \"r\", encoding=\"utf-8\") as file:\n",
        "          for line in file:\n",
        "              line = line.replace(\"\\n\", \"\")\n",
        "              parts = line.strip().split(maxsplit=1)\n",
        "              if len(parts) < 2:\n",
        "                  continue\n",
        "\n",
        "              true_label = parts[0].replace(\"__label__\", \"\")\n",
        "              text = parts[1]\n",
        "\n",
        "              try:\n",
        "                  pred_label = self.model.predict(text, k=1)[0][0].replace(\"__label__\", \"\")\n",
        "              except Exception as e:\n",
        "                  print(f\"Prediction failed on: {text[:50]} - {e}\")\n",
        "                  continue\n",
        "\n",
        "              cm[(true_label, pred_label)] += 1\n",
        "              n_samples += 1\n",
        "\n",
        "      return {\n",
        "          \"cm\": cm,\n",
        "          \"samples\": n_samples,\n",
        "          \"loss\": 1 - macro_f1(cm)\n",
        "      }\n",
        "\n",
        "\n",
        "    def fine_tune(self, epochs: list[int] = EPOCHS):\n",
        "        best_model = \"\"\n",
        "        best_val = {\"loss\": float('inf')}\n",
        "        wait = 0\n",
        "        for i in range(epochs[0], epochs[1]+1):\n",
        "            # Train the model\n",
        "            self.model = fasttext.train_supervised(input=f\"{TRAINING}.txt\", pretrainedVectors=FAST_TEXT + \".vec\", dim=PRETRAINED_DIM, epoch=i, lr=LR)\n",
        "\n",
        "            # Evaluate the model\n",
        "            val = self.validate()\n",
        "            print(f'Epoch {i} validation loss {val[\"loss\"]}')\n",
        "            if val[\"loss\"] < best_val[\"loss\"]:\n",
        "              best_model = f\"{TMP}/{i}.bin\"\n",
        "              self.model.save_model(best_model)\n",
        "              best_val = val\n",
        "              wait = 0\n",
        "            if wait > PATIENCE:\n",
        "              print(f\"Early stopped at epoch {i}\")\n",
        "              break\n",
        "            wait += 1\n",
        "\n",
        "        # Save the model\n",
        "        os.rename(best_model, \"/content/finetuned-model.bin\")\n",
        "        for i in range(epochs[0], epochs[1]+1):\n",
        "          path = f\"{TMP}/{i}.bin\"\n",
        "          if os.path.exists(path):\n",
        "            os.remove(path)\n",
        "\n",
        "\n",
        "    def benchmark(self, dataset:str = TEST, model_path:str = FINE_TUNED) -> float:\n",
        "        self.model = fasttext.load_model(model_path)\n",
        "\n",
        "        start = time.time()\n",
        "        i = 0\n",
        "        while time.time() - start < BENCHMARK_TIME_LIMIT:\n",
        "          self.model.test(f\"{dataset}.txt\")\n",
        "          i += 1\n",
        "\n",
        "        samples = 1\n",
        "        with open(f\"{dataset}.txt\") as file:\n",
        "          samples = sum(1 for _ in file)\n",
        "\n",
        "        return i * samples, time.time() - start\n",
        "\n",
        "    @staticmethod\n",
        "    def prepare_dataset():\n",
        "        assert os.path.exists(f\"{TRAINING}.csv\"), f\"{TRAINING}.csv not found\"\n",
        "        assert os.path.exists(f\"{VALIDATION}.csv\") , f\"{VALIDATION}.csv not found\"\n",
        "        assert os.path.exists(f\"{TEST}.csv\") , f\"{TEST}.csv not found\"\n",
        "\n",
        "        for dataset in [TRAINING, VALIDATION, TEST]:\n",
        "            FineFastText._write_txt(dataset)\n",
        "\n",
        "    @staticmethod\n",
        "    def _write_txt(dataset: str):\n",
        "        if os.path.exists(f\"{dataset}.txt\"):\n",
        "            if not OVERRIDE:\n",
        "              return\n",
        "            os.remove(f\"{dataset}.txt\")\n",
        "\n",
        "        txt = open(f\"{dataset}.txt\", \"a\", encoding=\"utf-8\")\n",
        "        file = open(f\"{dataset}.csv\", \"r\", encoding=\"utf-8\")\n",
        "\n",
        "        reader = csv.DictReader(file, delimiter=',')\n",
        "        for row in reader:\n",
        "          assert INPUT_COL in row , f\"row of dataset {dataset} doesn't have {INPUT_COL} attribute, it cointains {row.keys()}\"\n",
        "          assert OUT_COL in row, f\"row of dataset {dataset} doesn't have {OUT_COL} attribute, it cointains {row.keys()}\"\n",
        "\n",
        "          tweet = row[INPUT_COL]\n",
        "          if \"\\n\" in tweet:\n",
        "            tweet = tweet.replace(\"\\n\", \" _ENTER_ \")\n",
        "          txt.write(f\"__label__{row[OUT_COL]} {tweet}\\n\")\n",
        "\n",
        "        file.close()\n",
        "        txt.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-PWBQnWKg3qL",
        "outputId": "003e3de2-4ce8-4617-ea66-a739f4b76cc0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset ready\n"
          ]
        }
      ],
      "source": [
        "def binary_cm(metrics: dict):\n",
        "  cm = metrics[\"cm\"]\n",
        "  print(\"Binary model: Confusion matrix\")\n",
        "  print(\"\\t|Positive\\t|Negative\")\n",
        "  print(f\"True\\t|{cm[('1', '1')]}\\t\\t|{cm[('1', '0')]}\")\n",
        "  print(f\"False\\t|{cm[('0', '1')]}\\t\\t|{cm[('0', '0')]}\")\n",
        "\n",
        "def multiclass_cm(metrics: dict):\n",
        "    cm = metrics[\"cm\"]\n",
        "\n",
        "    # Define label order and mapping (you can replace these later)\n",
        "    labels = ['0', '1', '2', '3', '4'] # change to named labels\n",
        "    label_names = {label: label for label in labels}  # For now just identity mapping\n",
        "\n",
        "    # Header row\n",
        "    print(\"Multiclass Confusion Matrix\")\n",
        "    header = \"\\t|\" + \"\\t\".join(label_names[label] for label in labels)\n",
        "    print(header)\n",
        "\n",
        "    # Each row: true label\n",
        "    for true_label in labels:\n",
        "        row = [label_names[true_label]]\n",
        "        for pred_label in labels:\n",
        "            count = cm.get((true_label, pred_label), 0)\n",
        "            row.append(str(count))\n",
        "        print(\"\\t|\".join(row))\n",
        "\n",
        "# dataset preparation\n",
        "FineFastText.prepare_dataset()\n",
        "print(\"Dataset ready\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rLhIPUG2kUkW",
        "outputId": "5e2e4a68-7df0-4c8c-a0ec-88a580fa8315"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Fine tuning\n",
            "Epoch 18 validation loss 0.07693282142225133\n",
            "Epoch 19 validation loss 0.07691633875956505\n",
            "Epoch 20 validation loss 0.07689448327301152\n",
            "Epoch 21 validation loss 0.0771915292622658\n",
            "Epoch 22 validation loss 0.07714943684940734\n"
          ]
        }
      ],
      "source": [
        "# Fine tuning fasttext\n",
        "fast = FineFastText()\n",
        "print(\"\\nFine tuning\")\n",
        "fast.fine_tune()\n",
        "\n",
        "## Fine tuned model testing\n",
        "metrics = fast.validate(dataset = TEST)\n",
        "del fast"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DdmosuPDii1u",
        "outputId": "bc671b4c-b519-4922-815b-a67509cea9e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Multiclass Confusion Matrix\n",
            "\t|0\t1\t2\t3\t4\n",
            "0\t|751\t|4\t|2\t|18\t|1\n",
            "1\t|1\t|718\t|5\t|10\t|5\n",
            "2\t|3\t|4\t|666\t|83\t|8\n",
            "3\t|20\t|12\t|54\t|537\t|35\n",
            "4\t|0\t|5\t|2\t|32\t|770\n",
            "{'cm': defaultdict(<class 'int'>, {('3', '0'): 20, ('0', '0'): 751, ('2', '3'): 83, ('3', '3'): 537, ('2', '2'): 666, ('4', '4'): 770, ('1', '1'): 718, ('4', '3'): 32, ('3', '2'): 54, ('1', '2'): 5, ('0', '3'): 18, ('3', '4'): 35, ('3', '1'): 12, ('0', '1'): 4, ('0', '2'): 2, ('2', '4'): 8, ('4', '1'): 5, ('4', '2'): 2, ('1', '4'): 5, ('2', '0'): 3, ('1', '3'): 10, ('2', '1'): 4, ('0', '4'): 1, ('1', '0'): 1}), 'samples': 3746, 'loss': 0.08436633980280495}\n"
          ]
        }
      ],
      "source": [
        "# Metrics and confusion matrix print\n",
        "if MODE == \"binary\":\n",
        "  binary_cm(metrics)\n",
        "else:\n",
        "  multiclass_cm(metrics)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mYxL9X8gD3T2",
        "outputId": "124bc64c-459b-4443-ba63-24120af1c20c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.9188467698878804\n",
            "Macro F1: 0.915633660197195\n",
            "Micro F1: 0.9188467698878804\n"
          ]
        }
      ],
      "source": [
        "def accuracy(metrics: dict) -> float:\n",
        "    cm = metrics[\"cm\"]\n",
        "    total = sum(cm.values())\n",
        "    correct = sum(count for (true, pred), count in cm.items() if true == pred)\n",
        "    return correct / total if total > 0 else 0.0\n",
        "\n",
        "def macro_f1(metrics: dict) -> float:\n",
        "    cm = metrics[\"cm\"]\n",
        "    labels = sorted(set([k[0] for k in cm] + [k[1] for k in cm]))\n",
        "    f1s = []\n",
        "\n",
        "    for label in labels:\n",
        "        tp = cm.get((label, label), 0)\n",
        "        fp = sum(cm.get((other, label), 0) for other in labels if other != label)\n",
        "        fn = sum(cm.get((label, other), 0) for other in labels if other != label)\n",
        "\n",
        "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
        "        recall    = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "        f1        = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
        "        f1s.append(f1)\n",
        "\n",
        "    return sum(f1s) / len(f1s) if f1s else 0.0\n",
        "\n",
        "def micro_f1(metrics: dict) -> float:\n",
        "    cm = metrics[\"cm\"]\n",
        "    tp = sum(count for (true, pred), count in cm.items() if true == pred)\n",
        "    total = sum(cm.values())\n",
        "    return tp / total if total > 0 else 0.0\n",
        "\n",
        "\n",
        "print(\"Accuracy:\", accuracy(metrics))\n",
        "print(\"Macro F1:\", macro_f1(metrics))\n",
        "print(\"Micro F1:\", micro_f1(metrics))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DtEI7gougwNV",
        "outputId": "ac441450-328a-433f-81c2-1c4162d837c8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Benchmark finetuned, classified 2442392 samples in 60.090959310531616s.\n"
          ]
        }
      ],
      "source": [
        "fast = FineFastText()\n",
        "samples, total_time = fast.benchmark(model_path=FINE_TUNED)\n",
        "print(f\"Benchmark finetuned, classified {samples} samples in {total_time}s.\")\n",
        "del fast"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
