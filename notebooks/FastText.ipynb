{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_3_qQNGmlCoL",
        "outputId": "7740b215-858b-4710-f46f-46a081c375f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: fasttext in /usr/local/lib/python3.11/dist-packages (0.9.3)\n",
            "Requirement already satisfied: pybind11>=2.2 in /usr/local/lib/python3.11/dist-packages (from fasttext) (2.13.6)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from fasttext) (75.2.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from fasttext) (1.26.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install fasttext\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import fasttext"
      ],
      "metadata": {
        "id": "j6375VO8-Mrw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uFzG4ORblGQM"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "import os\n",
        "import time\n",
        "import math\n",
        "from collections import defaultdict\n",
        "\n",
        "MODE = \"multiclass\" # \"binary\" #\n",
        "OVERRIDE = False # Rewrites all .txt datasets\n",
        "\n",
        "ARTIFACTS = \"/content/drive/MyDrive/HLT_artifacts\"\n",
        "DATASET = f\"{ARTIFACTS}/datasets\"\n",
        "TRAINING = f\"{DATASET}/train_{MODE}\"\n",
        "VALIDATION = f\"{DATASET}/validation_{MODE}\"\n",
        "TEST = f\"{DATASET}/test_{MODE}\"\n",
        "\n",
        "FAST_TEXT = f\"{ARTIFACTS}/base_models/fasttext\"\n",
        "FINE_TUNED = f\"{ARTIFACTS}/fine-tuned_models/fasttext-{MODE}.bin\"\n",
        "TMP = \"/content\"\n",
        "\n",
        "PRETRAINED_DIM=300 # When ValueError: Dimension of pretrained vectors (x) does not match dimension (y)! set this var to x\n",
        "BENCHMARK_TIME_LIMIT = 60 * 1\n",
        "\n",
        "EPOCHS = [18, 22]\n",
        "PATIENCE = 2\n",
        "LR = 1e-2\n",
        "\n",
        "INPUT_COL = \"tweet_text\"\n",
        "OUT_COL = \"label\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def macro_f1(cm):\n",
        "    labels = sorted(set([k[0] for k in cm] + [k[1] for k in cm]))\n",
        "    f1s = []\n",
        "    for label in labels:\n",
        "        tp = cm.get((label, label), 0)\n",
        "        fp = sum(cm.get((other, label), 0) for other in labels if other != label)\n",
        "        fn = sum(cm.get((label, other), 0) for other in labels if other != label)\n",
        "\n",
        "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
        "        recall    = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "        f1        = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
        "        f1s.append(f1)\n",
        "\n",
        "    return sum(f1s) / len(f1s) if f1s else 0.0\n"
      ],
      "metadata": {
        "id": "qI196AK1naW0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FineFastText:\n",
        "    def __init__(self, model_path: str | None = None) -> None:\n",
        "        self.model = None\n",
        "        if model_path is not None:\n",
        "          self.model = fasttext.load_model(model_path + \".bin\")\n",
        "\n",
        "    def validate(self, dataset = VALIDATION) -> dict:\n",
        "      \"\"\"\n",
        "      Validation phase. Works for binary and multi-class.\n",
        "      Returns:\n",
        "          - loss (sum)\n",
        "          - confusion matrix as a dict: cm[(true, pred)] = count\n",
        "      \"\"\"\n",
        "      cm = defaultdict(int)\n",
        "      n_samples = 0\n",
        "\n",
        "      with open(f\"{dataset}.txt\", \"r\", encoding=\"utf-8\") as file:\n",
        "          for line in file:\n",
        "              line = line.replace(\"\\n\", \"\")\n",
        "              parts = line.strip().split(maxsplit=1)\n",
        "              if len(parts) < 2:\n",
        "                  continue\n",
        "\n",
        "              true_label = parts[0].replace(\"__label__\", \"\")\n",
        "              text = parts[1]\n",
        "\n",
        "              try:\n",
        "                  pred_labels = self.model.predict(text, k=1)[0]  # don't unpack probs\n",
        "                  pred_label = pred_labels[0].replace(\"__label__\", \"\")\n",
        "              except Exception as e:\n",
        "                  print(f\"Prediction failed on: {text[:50]} - {e}\")\n",
        "                  continue\n",
        "\n",
        "              cm[(true_label, pred_label)] += 1\n",
        "              n_samples += 1\n",
        "\n",
        "      return {\n",
        "          \"cm\": cm,\n",
        "          \"samples\": n_samples,\n",
        "          \"loss\": 1 - macro_f1(cm)\n",
        "      }\n",
        "\n",
        "\n",
        "    def fine_tune(self, epochs: list[int] = EPOCHS):\n",
        "        best_model = \"\"\n",
        "        best_val = {\"loss\": float('inf')}\n",
        "        wait = 0\n",
        "        for i in range(epochs[0], epochs[1]+1):\n",
        "            # Train the model\n",
        "            self.model = fasttext.train_supervised(input=f\"{TRAINING}.txt\", pretrainedVectors=FAST_TEXT + \".vec\", dim=PRETRAINED_DIM, epoch=i, lr=LR)\n",
        "\n",
        "            # Evaluate the model\n",
        "            val = self.validate()\n",
        "            print(f'Epoch {i} validation loss {val[\"loss\"]}')\n",
        "            if val[\"loss\"] < best_val[\"loss\"]:\n",
        "              best_model = f\"{TMP}/{i}.bin\"\n",
        "              self.model.save_model(best_model)\n",
        "              best_val = val\n",
        "              wait = 0\n",
        "            if wait > PATIENCE:\n",
        "              print(f\"Early stopped at epoch {i}\")\n",
        "              break\n",
        "            wait += 1\n",
        "\n",
        "        # Save the model\n",
        "        os.rename(best_model, \"/content/finetuned-model.bin\")\n",
        "        for i in range(epochs[0], epochs[1]+1):\n",
        "          path = f\"{TMP}/{i}.bin\"\n",
        "          if os.path.exists(path):\n",
        "            os.remove(path)\n",
        "\n",
        "\n",
        "    def benchmark(self, dataset:str = TEST, model_path:str = FINE_TUNED) -> float:\n",
        "        self.model = fasttext.load_model(model_path)\n",
        "\n",
        "        start = time.time()\n",
        "        i = 0\n",
        "        while time.time() - start < BENCHMARK_TIME_LIMIT:\n",
        "          self.model.test(f\"{dataset}.txt\")\n",
        "          i += 1\n",
        "\n",
        "        samples = 1\n",
        "        with open(f\"{dataset}.txt\") as file:\n",
        "          samples = sum(1 for _ in file)\n",
        "\n",
        "        return i * samples, time.time() - start\n",
        "\n",
        "    @staticmethod\n",
        "    def prepare_dataset():\n",
        "        assert os.path.exists(f\"{TRAINING}.csv\"), f\"{TRAINING}.csv not found\"\n",
        "        assert os.path.exists(f\"{VALIDATION}.csv\") , f\"{VALIDATION}.csv not found\"\n",
        "        assert os.path.exists(f\"{TEST}.csv\") , f\"{TEST}.csv not found\"\n",
        "\n",
        "        for dataset in [TRAINING, VALIDATION, TEST]:\n",
        "            FineFastText._write_txt(dataset)\n",
        "\n",
        "    @staticmethod\n",
        "    def _write_txt(dataset: str):\n",
        "        if os.path.exists(f\"{dataset}.txt\"):\n",
        "            if not OVERRIDE:\n",
        "              return\n",
        "            os.remove(f\"{dataset}.txt\")\n",
        "\n",
        "        txt = open(f\"{dataset}.txt\", \"a\", encoding=\"utf-8\")\n",
        "        file = open(f\"{dataset}.csv\", \"r\", encoding=\"utf-8\")\n",
        "\n",
        "        reader = csv.DictReader(file, delimiter=',')\n",
        "        for row in reader:\n",
        "          assert INPUT_COL in row , f\"row of dataset {dataset} doesn't have {INPUT_COL} attribute, it cointains {row.keys()}\"\n",
        "          assert OUT_COL in row, f\"row of dataset {dataset} doesn't have {OUT_COL} attribute, it cointains {row.keys()}\"\n",
        "\n",
        "          tweet = row[INPUT_COL]\n",
        "          if \"\\n\" in tweet:\n",
        "            tweet = tweet.replace(\"\\n\", \" _ENTER_ \")\n",
        "          txt.write(f\"__label__{row[OUT_COL]} {tweet}\\n\")\n",
        "\n",
        "        file.close()\n",
        "        txt.close()"
      ],
      "metadata": {
        "id": "sNq3e74okKDi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def binary_cm(metrics: dict):\n",
        "  cm = metrics[\"cm\"]\n",
        "  print(\"Binary model: Confusion matrix\")\n",
        "  print(\"\\t|Positive\\t|Negative\")\n",
        "  print(f\"True\\t|{cm[('1', '1')]}\\t\\t|{cm[('1', '0')]}\")\n",
        "  print(f\"False\\t|{cm[('0', '1')]}\\t\\t|{cm[('0', '0')]}\")\n",
        "\n",
        "def multiclass_cm(metrics: dict):\n",
        "    cm = metrics[\"cm\"]\n",
        "\n",
        "    # Define label order and mapping (you can replace these later)\n",
        "    labels = ['0', '1', '2']  # Change to ['toxic', 'insult', 'threat'] or similar\n",
        "    label_names = {label: label for label in labels}  # For now just identity mapping\n",
        "\n",
        "    # Header row\n",
        "    print(\"Multiclass Confusion Matrix\")\n",
        "    header = \"\\t|\" + \"\\t\".join(label_names[label] for label in labels)\n",
        "    print(header)\n",
        "\n",
        "    # Each row: true label\n",
        "    for true_label in labels:\n",
        "        row = [label_names[true_label]]\n",
        "        for pred_label in labels:\n",
        "            count = cm.get((true_label, pred_label), 0)\n",
        "            row.append(str(count))\n",
        "        print(\"\\t|\".join(row))\n",
        "\n",
        "# dataset preparation\n",
        "FineFastText.prepare_dataset()\n",
        "print(\"Dataset ready\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-PWBQnWKg3qL",
        "outputId": "c710de4c-834d-4332-f13b-32d6ee39909b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset ready\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fine tuning fasttext\n",
        "fast = FineFastText()\n",
        "print(\"\\nFine tuning\")\n",
        "fast.fine_tune()\n",
        "\n",
        "## Fine tuned model testing\n",
        "metrics = fast.validate(dataset = TEST)\n",
        "del fast"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rLhIPUG2kUkW",
        "outputId": "f0f4be83-2552-4afb-8d33-8976880218e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Fine tuning\n",
            "Epoch 18 validation loss 0.07693282142225133\n",
            "Epoch 19 validation loss 0.07691633875956505\n",
            "Epoch 20 validation loss 0.07689448327301152\n",
            "Epoch 21 validation loss 0.0771915292622658\n",
            "Epoch 22 validation loss 0.07714943684940734\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Metrics and confusion matrix print\n",
        "if MODE == \"binary\":\n",
        "  binary_cm(metrics)\n",
        "else:\n",
        "  multiclass_cm(metrics)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DdmosuPDii1u",
        "outputId": "2c47a810-496c-4d69-fcce-a27a9f56ef32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Multiclass Confusion Matrix\n",
            "\t|0\t1\t2\n",
            "0\t|751\t|4\t|2\n",
            "1\t|1\t|718\t|5\n",
            "2\t|3\t|4\t|666\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fast = FineFastText()\n",
        "samples, total_time = fast.benchmark(model_path=FINE_TUNED)\n",
        "print(f\"Benchmark finetuned, classified {samples} samples in {total_time}s.\")\n",
        "del fast"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DtEI7gougwNV",
        "outputId": "98ff34ae-f00f-4676-b19d-f7d03d4a81cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Benchmark finetuned, classified 2404932 samples in 60.11794948577881s.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}