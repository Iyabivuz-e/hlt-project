{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95367a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b12ea11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PATH = \"/Users/manuelemessere/Documents/Università /a) corsi/Human Language Technologies/HLT24_25/hlt_projct/cyberbullying\"\n",
    "sys.path.append(BASE_PATH)\n",
    "os.chdir(BASE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "549da248",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c6be149",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/manuelemessere/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from scripts import config\n",
    "from scripts.data_loader import DataLoader\n",
    "from scripts.data_understanding import DataUnderstanding\n",
    "from scripts.language_detection import LanguageDetector\n",
    "from scripts.data_cleaning import DataCleaner\n",
    "from scripts.text_preprocessing import TextPreprocessor\n",
    "from scripts.data_builder import DatasetBuilder\n",
    "from scripts.data_splitting import DataSplitter\n",
    "from scripts.data_saver import DataSaver"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f685c3",
   "metadata": {},
   "source": [
    "# Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a03d91cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded with shape: (47692, 2)\n"
     ]
    }
   ],
   "source": [
    "loader = DataLoader(config.RAW_DATA_PATH)\n",
    "df = loader.load_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "085c17e0",
   "metadata": {},
   "source": [
    "# Data understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5fadc9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "inspector = DataUnderstanding(df, text_column=config.TEXT_COLUMN, class_column=config.LABEL_COLUMN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9845dac3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Class Distribution:\n",
      "cyberbullying_type\n",
      "religion               7998\n",
      "age                    7992\n",
      "gender                 7973\n",
      "ethnicity              7961\n",
      "not_cyberbullying      7945\n",
      "other_cyberbullying    7823\n",
      "Name: count, dtype: int64\n",
      "--------------------------\n",
      "\n",
      "Class Imbalance Ratio (max/min): 1.02\n",
      "--------------------------\n",
      "\n",
      "Missing Values:\n",
      "tweet_text            0\n",
      "cyberbullying_type    0\n",
      "dtype: int64\n",
      "--------------------------\n",
      "\n",
      "Empty or whitespace-only strings per column:\n",
      "tweet_text            0\n",
      "cyberbullying_type    0\n",
      "dtype: int64\n",
      "--------------------------\n",
      "\n",
      "Number of duplicated tweet_text: 1675\n",
      "--------------------------\n",
      "\n",
      "Total duplicated texts (same text, any label): 3350 rows\n",
      "\n",
      "Label counts among all duplicates:\n",
      "other_cyberbullying: 1580\n",
      "not_cyberbullying: 1525\n",
      "gender: 226\n",
      "ethnicity: 11\n",
      "religion: 8\n",
      "\n",
      "Perfect duplicates (same text and same label): 72 rows\n",
      "Imperfect duplicates (same text, different labels): 3278 rows\n",
      "--------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/manuelemessere/Documents/Università /a) corsi/Human Language Technologies/HLT24_25/hlt_projct/cyberbullying/scripts/data_understanding.py:44: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  .applymap(lambda x: isinstance(x, str) and x.strip() == '')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Hashtags per Tweet: 0.24\n",
      "--------------------------\n",
      "\n",
      "Average Emojis per Tweet: 0.02\n"
     ]
    }
   ],
   "source": [
    "inspector.class_distribution()\n",
    "\n",
    "print(\"--------------------------\")\n",
    "\n",
    "inspector.check_imbalance()\n",
    "\n",
    "print(\"--------------------------\")\n",
    "\n",
    "inspector.check_missing_values()\n",
    "\n",
    "print(\"--------------------------\")\n",
    "\n",
    "inspector.check_empty_strings()\n",
    "\n",
    "print(\"--------------------------\")\n",
    "\n",
    "inspector.check_duplicates()\n",
    "\n",
    "print(\"--------------------------\")\n",
    "\n",
    "inspector.inspect_duplicates()\n",
    "\n",
    "print(\"--------------------------\")\n",
    "\n",
    "inspector.hashtag_analysis()\n",
    "\n",
    "print(\"--------------------------\")\n",
    "\n",
    "inspector.emoji_analysis()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec54794",
   "metadata": {},
   "source": [
    "# Language filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3ccb684",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for English language only\n",
    "lang_detector = LanguageDetector(target_lang=config.LANGUAGE)\n",
    "df[\"is_en\"] = df[config.TEXT_COLUMN].astype(str).apply(lang_detector.is_target_language)\n",
    "df = df[df[\"is_en\"] == True].drop(columns=[\"is_en\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf899de3",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ddde3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out 'other_cyberbullying' from the dataset\n",
    "df = df[df['cyberbullying_type'] != 'other_cyberbullying'].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9f3e1d7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['not_cyberbullying' 'gender' 'religion' 'age' 'ethnicity']\n"
     ]
    }
   ],
   "source": [
    "print(df['cyberbullying_type'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "376576c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaner = DataCleaner(df, text_column='tweet_text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9c53b25c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Before removing -----\n",
      "Total rows numbers: 37751\n",
      "Only text duplicates (tweet_text): 91\n",
      "Text duplicates + label (tweet_text + cyberbullying_type): 35\n"
     ]
    }
   ],
   "source": [
    "# --- Before cleaning, duplicates analysis ---\n",
    "print(\"----- Before removing -----\")\n",
    "print(f\"Total rows numbers: {df.shape[0]}\")\n",
    "print(f\"Only text duplicates (tweet_text): {df.duplicated(subset=['tweet_text']).sum()}\")\n",
    "print(f\"Text duplicates + label (tweet_text + cyberbullying_type): {df.duplicated(subset=['tweet_text', 'cyberbullying_type']).sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fcf36ec2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- CLEANING DUPLICATES COLUMN BY COLUMN: ['tweet_text'] ---\n",
      "\n",
      "Processing column: 'tweet_text'\n",
      " - Removed 112 imperfect duplicates (conflicting labels)\n",
      " - Removed 35 perfect duplicates (keeping one)\n",
      "\n",
      "Total rows removed: 147\n",
      "--- DUPLICATE CLEANING COMPLETED ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/manuelemessere/Documents/Università /a) corsi/Human Language Technologies/HLT24_25/hlt_projct/cyberbullying/scripts/data_cleaning.py:40: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  duplicates_imperfect = duplicates_all[\n"
     ]
    }
   ],
   "source": [
    "# Duplicates removing\n",
    "cleaned_df = cleaner.clean_text_duplicates()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8bd2a3ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----- After removing -----\n",
      "Total rows numbers controll: 37604\n",
      "Only text duplicates controll (tweet_text): 0\n",
      "Duplicati su testo + label controll (tweet_text + cyberbullying_type): 0\n"
     ]
    }
   ],
   "source": [
    "# --- After cleaning---\n",
    "print(\"\\n----- After removing -----\")\n",
    "print(f\"Total rows numbers controll: {cleaned_df.shape[0]}\")\n",
    "print(f\"Only text duplicates controll (tweet_text): {cleaned_df.duplicated(subset=['tweet_text']).sum()}\")\n",
    "print(f\"Duplicati su testo + label controll (tweet_text + cyberbullying_type): {cleaned_df.duplicated(subset=['tweet_text', 'cyberbullying_type']).sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6be884a",
   "metadata": {},
   "source": [
    "# Text preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ae72a2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = TextPreprocessor()\n",
    "cleaned_df[\"tweet_soft\"] = cleaned_df[config.TEXT_COLUMN].astype(str).apply(preprocessor.clean_text_soft)\n",
    "cleaned_df[\"tweet_full\"] = cleaned_df[config.TEXT_COLUMN].astype(str).apply(preprocessor.clean_text_full)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe3a48c",
   "metadata": {},
   "source": [
    "# Preprocessed dataset building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "62191fbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset saved to /Users/manuelemessere/Documents/Università /a) corsi/Human Language Technologies/HLT24_25/hlt_projct/cyberbullying/data/processed_data/dataset_preprocessed.csv.\n"
     ]
    }
   ],
   "source": [
    "# Preprocessed full dataset, for checking and working on it\n",
    "builder = DatasetBuilder(cleaned_df)\n",
    "builder.add_binary_label()\n",
    "builder.add_multiclass_label()\n",
    "cleaned_df = builder.df\n",
    "\n",
    "# Saving preprocessed dataset\n",
    "saver = DataSaver()\n",
    "saver.save_dataframe(cleaned_df, os.path.join(config.PROCESSED_DATA_PATH, \"dataset_preprocessed.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c899778d",
   "metadata": {},
   "source": [
    "# Data splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4d793947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: 26698 samples\n",
      "Validation set: 7145 samples\n",
      "Test set: 3761 samples\n",
      "Dataset saved to /Users/manuelemessere/Documents/Università /a) corsi/Human Language Technologies/HLT24_25/hlt_projct/cyberbullying/data/interim/train.csv.\n",
      "Dataset saved to /Users/manuelemessere/Documents/Università /a) corsi/Human Language Technologies/HLT24_25/hlt_projct/cyberbullying/data/interim/val.csv.\n",
      "Dataset saved to /Users/manuelemessere/Documents/Università /a) corsi/Human Language Technologies/HLT24_25/hlt_projct/cyberbullying/data/interim/test.csv.\n"
     ]
    }
   ],
   "source": [
    "# Splitting dataset\n",
    "splitter = DataSplitter(cleaned_df, label_column=config.BINARY_LABEL_COLUMN, random_state=config.SEED)\n",
    "train_df, val_df, test_df = splitter.split()\n",
    "\n",
    "# Saving splitted data\n",
    "if config.SAVE_SPLITS:\n",
    "    saver = DataSaver()\n",
    "    saver.save_dataframe(train_df, os.path.join(config.INTERIM_DATA_PATH, \"train.csv\"))\n",
    "    saver.save_dataframe(val_df, os.path.join(config.INTERIM_DATA_PATH, \"val.csv\"))\n",
    "    saver.save_dataframe(test_df, os.path.join(config.INTERIM_DATA_PATH, \"test.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e62440c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
